{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import mixture\n",
    "from numpy import linalg\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#import dataset\n",
    "dataset = pd.read_csv('pid-5M.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data vis 1: plot correlation grid (on the raw data)\n",
    "\n",
    "data = pd.read_csv('pid-5M.csv')\n",
    "data.dataframeName = 'pid-5M.csv'\n",
    "\n",
    "def plotCorrelationMatrix(df, graphWidth):\n",
    "    filename = df.dataframeName\n",
    "    df = df.dropna('columns') # drop columns with NaN\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
    "    if df.shape[1] < 2:\n",
    "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
    "        return\n",
    "    corr = df.corr()\n",
    "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
    "    corrMat = plt.matshow(corr, fignum = 1)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    plt.gca().xaxis.tick_bottom()\n",
    "    plt.colorbar(corrMat)\n",
    "    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "plotCorrelationMatrix(data,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data vis 2: scatter plots for each feature against other features\n",
    "\n",
    "def plotScatterMatrix(df, plotSize, textSize):\n",
    "    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n",
    "    # Remove rows and columns that would lead to df being singular\n",
    "    df = df.dropna('columns')\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
    "    columnNames = list(df)\n",
    "    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n",
    "        columnNames = columnNames[:10]\n",
    "    df = df[columnNames]\n",
    "    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n",
    "    corrs = df.corr().values\n",
    "    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n",
    "        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n",
    "    plt.suptitle('Scatter and Density Plot')\n",
    "    plt.show()\n",
    "    \n",
    "plotScatterMatrix(data,20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split up data \n",
    "\n",
    "X = np.array(data.drop(\"id\", axis = 1))\n",
    "y = np.array(data[\"id\"])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_true = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different modified data sets with training and testing data for each modification  --------------------------------\n",
    "\n",
    "# A) unmodified data set\n",
    "dfA = np.asarray(data)\n",
    "X_train_A = X_train\n",
    "X_test_A = X_test\n",
    "y_train_A = y_train\n",
    "y_true_A = y_true\n",
    "\n",
    "# B) data set with all observations with zero values for inner or outer energy removed  -----------------------------\n",
    "b = True\n",
    "if (b == True):\n",
    "    global Xb\n",
    "    Xb = X\n",
    "    temp = Xb[:,4] != 0\n",
    "    Xb = Xb[temp]\n",
    "    temp = Xb[:,5] != 0\n",
    "    Xb = Xb[temp]\n",
    "    global yb\n",
    "    yb = y\n",
    "    yb = yb[temp]\n",
    "    \n",
    "    X_train_B, X_test_B, y_train_B, y_true_B = train_test_split(Xb, yb, test_size = 0.2)\n",
    "    \n",
    "\n",
    "# C) data set with all outer and inner energy features removed      -------------------------------------------\n",
    "c = True\n",
    "if (c == True):\n",
    "    global X_train_C\n",
    "    X_train_C = X_train_A[:,0:4]\n",
    "    global X_test_C\n",
    "    X_test_C = X_test_A[:,0:4]\n",
    "    global y_train_C\n",
    "    y_train_C = y_train_A\n",
    "    global y_true_C\n",
    "    y_true_C = y_true_A\n",
    "    \n",
    "\n",
    "# D) data set with zero values for outer and inner energy replaced with label averages for inner and outer energy\n",
    "d = True\n",
    "if (d == True):\n",
    "    global dfD\n",
    "    dfD = dfA\n",
    "    labels = [211., 321., -11., 2212.]\n",
    "    for label in labels:\n",
    "        is_label = dfD == label\n",
    "        label_features = dfD[is_label[:,0],5:7]\n",
    "        label_averages = np.sum(label_features, axis=0)/label_features.shape[0]\n",
    "        dfD[np.where(dfD[:,5]==0),5]=label_averages[0]\n",
    "        dfD[np.where(dfD[:,6]==0),6]=label_averages[1]\n",
    "    Xd = dfD[:,1:-1]   \n",
    "    X_train_D, X_test_D, y_train_D, y_true_D = train_test_split(Xd, y, test_size = 0.2)\n",
    "        \n",
    "# E) PCA     -------------------------------------------------------------------------------------------\n",
    "\n",
    "X = dfA[:,1:7]\n",
    "y = dfA[:,0]\n",
    "feature_number = range(7)\n",
    "# This is how you would normally deterimine the cross-validation scores for factor loading matrix (PCA & FA) of rank < 7, but it takes > 14 hours, so the scores are recorded manually.\n",
    "#\n",
    "# feature_number = range(7)\n",
    "# def compute_scores(X):\n",
    "#    pca = PCA(svd_solver='full')\n",
    "#    fa = FactorAnalysis()\n",
    "#    pca_scores = []\n",
    "#    fa_scores = []\n",
    "#    for n in feature_number:\n",
    "#        pca.n_components = n\n",
    "#        fa.n_components = n\n",
    "#        pca_scores.append(np.mean(cross_val_score(pca, X)))\n",
    "#        fa_scores.append(np.mean(cross_val_score(fa, X)))\n",
    "#    return pca_scores , fa_scores\n",
    "# pca_scores, fa_scores = compute_scores(X)\n",
    "\n",
    "pca_scores = [-20.417304627720515, -6.337975461158428, -3.2960940429579977, -2.422670031401208, -2.3466500178010197, -2.326699703481935, -2.326699703481893]\n",
    "fa_scores = [-2.8688666472682827, -2.863668467090598, -2.3627710341253514, -2.326786520577398, -2.3266997211578873, -2.326699706167654, -2.62355281624038]\n",
    "n_components_pca = feature_number[np.argmax(pca_scores)]\n",
    "n_components_fa = feature_number[np.argmax(fa_scores)]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(feature_number, pca_scores, 'b', label='PCA scores')\n",
    "plt.plot(feature_number, fa_scores, 'r', label='FA scores')\n",
    "plt.axvline(n_components_pca, color='b',label='PCA CV: %d' % n_components_pca, linestyle='--')\n",
    "plt.axvline(n_components_fa, color='r', label='FactorAnalysis CV: %d' % n_components_fa, linestyle='--')\n",
    "\n",
    "pca = PCA(svd_solver='full', n_components='mle')\n",
    "pca.fit(X)\n",
    "n_components_pca_mle = pca.n_components_\n",
    "plt.axvline(n_components_pca_mle, color='k', label='PCA MLE: %d' % n_components_pca_mle, linestyle='--')\n",
    "\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('CV scores')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#fa = FactorAnalysis()\n",
    "#fa.n_components = 5\n",
    "#fa_data = fa.fit_transform(X)\n",
    "\n",
    "pca_data = pca.fit_transform(X)\n",
    "X_train_E, X_test_E, y_train_E, y_true_E = train_test_split(pca_data, y, test_size = 0.2)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#check to make sure that there are 4 unique labels in both the test and train data sets for all data sets above\n",
    "print('A')\n",
    "y_test_array = np.array(y_train_A)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(y_test_number)\n",
    "y_test_array = np.array(y_true_A)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(y_test_number)\n",
    "\n",
    "print('B')\n",
    "y_test_array = np.array(y_train_B)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(y_test_number)\n",
    "y_test_array = np.array(y_true_B)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(y_test_number)\n",
    "\n",
    "print('C')\n",
    "y_test_array = np.array(y_train_C)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(y_test_number)\n",
    "y_test_array = np.array(y_true_C)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(y_test_number)\n",
    "\n",
    "print('D')\n",
    "y_test_array = np.array(y_train_D)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(y_test_number)\n",
    "y_test_array = np.array(y_true_D)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(y_test_number)\n",
    "\n",
    "print('E')\n",
    "y_test_array = np.array(y_train_E)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(y_test_number)\n",
    "y_test_array = np.array(y_true_E)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(y_test_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "tic = time.perf_counter()\n",
    "#Ftting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg_classifier = LogisticRegression(random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "lg_classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predicting the Test set results\n",
    "y_pred = lg_classifier.predict(X_test)\n",
    "\n",
    "#In the prediction, there are only three classes, as we can see from the code below to print out the values in y_pred\n",
    "y_test_array = np.array(y_pred)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(\"Classes: \" + str(y_test_number))\n",
    "\n",
    "\n",
    "#Calculating accuracy for Logistic Regression\n",
    "from sklearn.metrics import accuracy_score\n",
    "toc = time.perf_counter()\n",
    "print(\"Accuracy from Logistic Regression is: \"+ str(accuracy_score(y_test, y_pred)))\n",
    "print(\"Runtime is: \" + str(toc-tic)+ \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: [ -11.  211.  321. 2212.]\n",
      "Accuracy from Navie Bayes is: 0.8530624\n",
      "Runtime is: 2.7941019300001244s\n"
     ]
    }
   ],
   "source": [
    "#Navie Bayes\n",
    "tic = time.perf_counter()\n",
    "#Ftting Navie Bayes to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predicting the Test set results\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "#In the prediction, there are only three classes, as we can see from the code below to print out the values in y_pred\n",
    "y_test_array = np.array(y_pred)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(\"Classes: \" + str(y_test_number))\n",
    "\n",
    "\n",
    "#Calculating accuracy for Navie Bayes\n",
    "from sklearn.metrics import accuracy_score\n",
    "toc = time.perf_counter()\n",
    "print(\"Accuracy from Navie Bayes is: \"+ str(accuracy_score(y_test, y_pred)))\n",
    "print(\"Runtime is: \" + str(toc-tic)+ \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "tic = time.perf_counter()\n",
    "#Ftting SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "svm_classifier = SVC(kernal = 'linear', random_state = 0)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predicting the Test set results\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "#In the prediction, there are only three classes, as we can see from the code below to print out the values in y_pred\n",
    "y_test_array = np.array(y_pred)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(\"Classes: \" + str(y_test_number))\n",
    "\n",
    "#Calculating accuracy for SVM\n",
    "from sklearn.metrics import accuracy_score\n",
    "toc = time.perf_counter()\n",
    "print(\"Accuracy from SVM is: \"+ str(accuracy_score(y_test, y_pred)))\n",
    "print(\"Runtime is: \" + str(toc-tic)+ \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -11.  211.  321. 2212.]\n",
      "Accuracy from Neural Network is: \n",
      "0.970252\n"
     ]
    }
   ],
   "source": [
    "#Neural Network\n",
    "tic = time.perf_counter()\n",
    "#Ftting Neural Network to the Training set\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nn_classifier = MLPClassifier(random_state = 0)\n",
    "nn_classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predicting the Test set results\n",
    "y_pred = nn_classifier.predict(X_test)\n",
    "\n",
    "#In the prediction, there are only three classes, as we can see from the code below to print out the values in y_pred\n",
    "y_test_array = np.array(y_pred)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(\"Classes: \" + str(y_test_number))\n",
    "\n",
    "\n",
    "#Calculating accuracy for SVM\n",
    "from sklearn.metrics import accuracy_score\n",
    "toc = time.perf_counter()\n",
    "print(\"Accuracy from Neural Network is: \"+ str(accuracy_score(y_test, y_pred)))\n",
    "print(\"Runtime is: \" + str(toc-tic)+ \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: [ -11.  211.  321. 2212.]\n",
      "Accuracy from Neural Network is: 0.959076\n",
      "Runtime is: 117.4481621089999s\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "tic = time.perf_counter()\n",
    "#Ftting Neural Network to the Training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predicting the Test set results\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "#In the prediction, there are only three classes, as we can see from the code below to print out the values in y_pred\n",
    "y_test_array = np.array(y_pred)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(\"Classes: \" + str(y_test_number))\n",
    "\n",
    "\n",
    "#Calculating accuracy for SVM\n",
    "from sklearn.metrics import accuracy_score\n",
    "toc = time.perf_counter()\n",
    "print(\"Accuracy from Neural Network is: \"+ str(accuracy_score(y_test, y_pred)))\n",
    "print(\"Runtime is: \" + str(toc-tic)+ \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "tic = time.perf_counter()\n",
    "#Ftting Neural Network to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(,criterion = 'entropy', random_state = 0)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predicting the Test set results\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "#In the prediction, there are only three classes, as we can see from the code below to print out the values in y_pred\n",
    "y_test_array = np.array(y_pred)\n",
    "y_test_number = np.unique(y_test_array)\n",
    "print(\"Classes: \" + str(y_test_number))\n",
    "\n",
    "\n",
    "#Calculating accuracy for SVM\n",
    "from sklearn.metrics import accuracy_score\n",
    "toc = time.perf_counter()\n",
    "print(\"Accuracy from Neural Network is: \"+ str(accuracy_score(y_test, y_pred)))\n",
    "print(\"Runtime is: \" + str(toc-tic)+ \"s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
