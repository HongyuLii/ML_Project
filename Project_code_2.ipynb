{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import itertools\n",
    "\n",
    "#import dataset\n",
    "data = pd.read_csv('pid-5M.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data vis 1: plot correlation grid (on the raw data)\n",
    "data.dataframeName = 'pid-5M.csv'\n",
    "\n",
    "def plotCorrelationMatrix(df, graphWidth):\n",
    "    filename = df.dataframeName\n",
    "    df = df.dropna('columns') # drop columns with NaN\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
    "    if df.shape[1] < 2:\n",
    "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
    "        return\n",
    "    corr = df.corr()\n",
    "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
    "    corrMat = plt.matshow(corr, fignum = 1)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    plt.gca().xaxis.tick_bottom()\n",
    "    plt.colorbar(corrMat)\n",
    "    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "plotCorrelationMatrix(data,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data vis 2: scatter plots for each feature against other features\n",
    "\n",
    "def plotScatterMatrix(df, plotSize, textSize):\n",
    "    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n",
    "    # Remove rows and columns that would lead to df being singular\n",
    "    df = df.dropna('columns')\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
    "    columnNames = list(df)\n",
    "    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n",
    "        columnNames = columnNames[:10]\n",
    "    df = df[columnNames]\n",
    "    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n",
    "    corrs = df.corr().values\n",
    "    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n",
    "        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n",
    "    plt.suptitle('Scatter and Density Plot')\n",
    "    plt.show()\n",
    "    \n",
    "plotScatterMatrix(data,20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split up data \n",
    "\n",
    "D = np.array(data)\n",
    "X = D[:,1:7]\n",
    "y = D[:,0]\n",
    "\n",
    "#different modified data sets with training and testing data for each modification  --------------------------------\n",
    "\n",
    "# A) unmodified data set\n",
    "def datasetA():\n",
    "    return X, y\n",
    "\n",
    "# B) data set with all observations with zero values for inner or outer energy removed  -----------------------------\n",
    "def datasetB():\n",
    "    filterIx = (X[:,4] != 0) & (X[:,5] != 0)\n",
    "    return X[filterIx], y[filterIx]\n",
    "    \n",
    "# C) data set with all outer and inner energy features removed      -------------------------------------------\n",
    "def datasetC():\n",
    "    return X[:,0:4], y\n",
    "    \n",
    "# D) data set with zero values for outer and inner energy replaced with label averages for inner and outer energy\n",
    "def datasetD():\n",
    "    labels = [211., 321., -11., 2212.]\n",
    "    for label in labels:\n",
    "        label_features = D[y == label, 5:7]\n",
    "        label_averages = np.sum(label_features, axis=0)/label_features.shape[0]\n",
    "        D[np.where(D[:,5]==0), 5] = label_averages[0]\n",
    "        D[np.where(D[:,6]==0), 6] = label_averages[1]\n",
    "    return D[:,1:-1], y\n",
    "        \n",
    "# E) PCA     -------------------------------------------------------------------------------------------\n",
    "def datasetE():\n",
    "    from sklearn.decomposition import PCA\n",
    "    return PCA(svd_solver='full', n_components='mle').fit_transform(X), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building models...\n",
      "Building datasets...\n",
      "Running models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LogisticRegression on data set 1) (0.9159114634552249, array([ -11.,  211., 2212.]), 60.59097301000293)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LogisticRegression on data set 0) (0.918399, array([ -11.,  211.,  321., 2212.]), 135.36239122400002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-29:\n",
      "Process ForkPoolWorker-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"<ipython-input-22-034552bf3976>\", line 15, in run_model\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\", line 1606, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\", line 944, in _logistic_regression_path\n",
      "    iprint=iprint, pgtol=tol, maxiter=max_iter)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\", line 199, in fmin_l_bfgs_b\n",
      "    **opts)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\", line 335, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\", line 285, in func_and_grad\n",
      "    f = fun(x, *args)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\", line 326, in function_wrapper\n",
      "    return function(*(wrapper_args + args))\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\", line 64, in __call__\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\", line 919, in <lambda>\n",
      "    func = lambda x, *args: _multinomial_loss_grad(x, *args)[0:2]\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\", line 346, in _multinomial_loss_grad\n",
      "    diff = sample_weight * (p - Y)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"<ipython-input-22-034552bf3976>\", line 15, in run_model\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\", line 1606, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\", line 944, in _logistic_regression_path\n",
      "    iprint=iprint, pgtol=tol, maxiter=max_iter)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\", line 199, in fmin_l_bfgs_b\n",
      "    **opts)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\", line 335, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\", line 285, in func_and_grad\n",
      "    f = fun(x, *args)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\", line 326, in function_wrapper\n",
      "    return function(*(wrapper_args + args))\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\", line 64, in __call__\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\", line 919, in <lambda>\n",
      "    func = lambda x, *args: _multinomial_loss_grad(x, *args)[0:2]\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\", line 344, in _multinomial_loss_grad\n",
      "    loss, p, w = _multinomial_loss(w, X, Y, alpha, sample_weight)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\", line 294, in _multinomial_loss\n",
      "    p -= logsumexp(p, axis=1)[:, np.newaxis]\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/scipy/special/_logsumexp.py\", line 101, in logsumexp\n",
      "    a_max = np.amax(a, axis=axis, keepdims=True)\n",
      "  File \"<__array_function__ internals>\", line 6, in amax\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\", line 2621, in amax\n",
      "    keepdims=keepdims, initial=initial, where=where)\n",
      "  File \"/Users/josephdenman/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\", line 90, in _wrapreduction\n",
      "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-034552bf3976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-034552bf3976>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mrun_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-034552bf3976>\u001b[0m in \u001b[0;36mrun_models\u001b[0;34m(models, datasets)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         return np.array(\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         ).reshape((len(models), len(datasets), 3))\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         '''\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# returns (accuracy score, # classes, running time)\n",
    "def run_model(model, dataset):\n",
    "    model_name = type(model).__name__\n",
    "    model_count = dataset[0]\n",
    "    from time import perf_counter\n",
    "    tick = perf_counter()\n",
    "    X_train, X_test, y_train, y_test = dataset[1]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    tock = perf_counter()\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    result = accuracy_score(y_test, y_pred), np.unique(np.array(y_pred)), tock - tick\n",
    "    print(\"(\" + model_name + \" on data set \" + str(model_count) + \")\", result)\n",
    "    return result\n",
    "\n",
    "\n",
    "# returns (model, dataset) matrix of (accuracy score, # classes, running time) results\n",
    "def run_models(models, datasets):\n",
    "    print(\"Running models...\")\n",
    "    from multiprocessing import Pool\n",
    "    with Pool(processes = 4) as pool:\n",
    "        return np.array(\n",
    "            pool.starmap(run_model,[(model, dataset) for model in models for dataset in datasets])\n",
    "        ).reshape((len(models), len(datasets), 3))\n",
    "    \n",
    "    \n",
    "# Include models\n",
    "def build_models():\n",
    "    print(\"Building models...\")\n",
    "    lg_classifier = LogisticRegression(random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "    nb_classifier = GaussianNB()\n",
    "    nn_classifier = MLPClassifier(random_state = 0)\n",
    "    dt_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    rf_classifier = RandomForestClassifier(criterion = 'entropy', random_state = 0)\n",
    "    return [lg_classifier, nb_classifier, nn_classifier, dt_classifier, rf_classifier]\n",
    "    \n",
    "    \n",
    "def generate_dataset(i, dataset_generator):\n",
    "    X, y = dataset_generator()\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    dataset = X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    while (len(np.unique(y_train)) != 4 or len(np.unique(y_test)) != 4):\n",
    "        dataset = X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    return i, dataset\n",
    "\n",
    "\n",
    "# Include datasets (datasetX)\n",
    "def build_datasets():\n",
    "    print(\"Building datasets...\")\n",
    "    return [generate_dataset(i, dataset_generator) for i, dataset_generator in enumerate([datasetA, datasetB, datasetC, datasetD, datasetE])]\n",
    "\n",
    "# WIP\n",
    "def render_results(results):\n",
    "    print(\"Rendering results...\")\n",
    "    plt.matshow(results)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def run():\n",
    "    models = build_models()\n",
    "    datasets = build_datasets()\n",
    "    run_models(models, datasets)\n",
    "    \n",
    "    \n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
